

# **Feasibility Analysis of tag\_invoke Generation Mechanisms for the TInCuP Tool**

## **The tag\_invoke Customization Paradigm in Modern C++**

To accurately assess the feasibility of integrating tag\_invoke support into the TInCuP tool, it is imperative to first establish a comprehensive understanding of the tag\_invoke mechanism itself. This paradigm is not an isolated language feature but rather the culmination of decades of evolution in C++ library design, specifically addressing the long-standing challenges of creating robust, extensible, and non-intrusive customization points. Its design directly informs the architectural choices and trade-offs inherent in any tooling built to support it. An examination of its history, anatomy, and potential future trajectory provides the necessary context for evaluating the proposed generation mechanisms.

### **1.1. The Evolution from ADL Overload Sets to tag\_invoke**

The ability for a library to delegate the behavior of an operation to a user-provided implementation is a cornerstone of generic programming in C++.1 For years, the standard and most widely adopted mechanism for achieving this has been the "classic" customization point, which relies on Argument-Dependent Lookup (ADL).  
The canonical example of this pattern is std::swap. Generic code intending to swap two objects of an unknown type T must perform a specific two-step dance: first, bring std::swap into the current scope with a using-declaration, and second, make an unqualified call to swap(a, b).1 This pattern allows ADL to search the namespaces associated with the types of  
a and b. If a user has provided a swap overload in the same namespace as their custom type, ADL will discover and prefer that overload; otherwise, the call will resolve to the generic std::swap template.2 While functional, this approach is fraught with subtle issues that have proven to be significant liabilities in large-scale software development.  
The most critical flaw is the effective pollution of the global namespace. Because the customization function is found via an unqualified call, its name (e.g., swap, begin, end) is effectively reserved across all namespaces that might participate in ADL.3 This creates a high probability of name collisions, where two independent libraries might attempt to use the same function name as a customization point but with entirely different semantics or constraints. Such a collision can lead to ambiguous overload resolution or, worse, the silent selection of an incorrect implementation.5  
A second major deficiency, and a primary motivator for a new solution, is the "wrapper transparency problem." Many advanced C++ designs rely on wrapper types, such as type-erasing wrappers (std::function, std::any), smart pointers, or property-decorating adapters for executors. With classic ADL-based CPOs, there is no generic mechanism for a wrapper to forward a customization call to the underlying wrapped object.3 Each CPO would require specialized forwarding logic within the wrapper, making generic, transparent wrappers exceptionally difficult to implement correctly.  
Finally, the classic ADL pattern is brittle with respect to modern C++ concepts and constraints. If the standard library were to place a concept constraint on std::begin, this constraint would have no effect on code that uses the idiomatic using std::begin; begin(a); pattern if ADL finds a user-defined, unconstrained begin overload. The constraint on the default implementation is completely bypassed, undermining the goal of centralized type checking and leading to less clear error messages.6  
The tag\_invoke mechanism, as proposed in P1895R0, was designed to solve these problems in a unified manner.5 It introduces a single, unique ADL target for all customizations: a free function named  
tag\_invoke.4 By funneling all customization through this single name, it eliminates the global name collision problem. Disambiguation is achieved by passing a unique "tag type" associated with the specific Customization Point Object (CPO) as the first argument to  
tag\_invoke. This allows the compiler to use standard overload resolution on the first argument to select the correct implementation, effectively namespacing the customization within the tag\_invoke overload set.5 This design provides a uniform interface for customization, solves the wrapper transparency problem by giving wrappers a single function to generically forward, and allows CPOs to enforce constraints before attempting the dispatch.

### **1.2. Anatomy of a tag\_invoke-based Customization Point**

A well-formed customization point based on the tag\_invoke pattern consists of three distinct but cooperative components: the Customization Point Object (CPO), its associated tag type, and the user-provided tag\_invoke overload.  
**The Customization Point Object (CPO):** The CPO is the public-facing entry point that library users interact with. It is formally defined as a const function object of a literal semiregular class type.10 Its primary responsibility is to encapsulate the invocation logic. The  
operator() of the CPO takes the user's arguments, forwards them, and dispatches the call to the tag\_invoke free function.12 This design is crucial because it solves the invocation problem of classic ADL. Instead of remembering the  
using std::swap; swap(a, b); ceremony, a user can simply make a direct, qualified call like std::ranges::swap(a, b), and the CPO guarantees that the correct customization will be found.6 Because the CPO is an object, it can be passed as an argument to higher-order functions (e.g.,  
std::transform(..., std::ranges::begin)), a capability that a simple function overload set does not provide.1  
**The Tag Type:** Each CPO is inextricably linked to a unique, corresponding tag type. For a CPO named compute::formula, its tag type might be compute::formula\_t.14 This type has no behavior; its sole purpose is to act as a unique identifier—a "tag"—for its CPO. When a user provides a customization, this tag type is used as the type of the first parameter to their  
tag\_invoke function. This is the key to the entire mechanism. The CPO's operator() invokes the free function tag\_invoke with an instance of its tag type as the first argument. This allows the compiler's overload resolution to distinguish between tag\_invoke overloads intended for compute::formula and those intended for any other CPO, preventing ambiguity and ensuring the correct customization is selected.5  
**The tag\_invoke Overload:** This is the part the end-user implements to customize the CPO's behavior for their specific type. It is a non-member function named tag\_invoke. Its signature must match the call made by the CPO: the first parameter is the CPO's tag type, followed by the arguments that were passed to the CPO itself.14 To be discoverable by the CPO's dispatch mechanism, this overload must be findable via ADL.  
The canonical and most effective pattern for defining this overload is as a **hidden friend function** inside the user's class definition.14 For a type  
custom\_compute customizing the compute::formula CPO, the implementation would look like:

C++

struct custom\_compute {  
private:  
    friend float tag\_invoke(compute::formula\_t, const custom\_compute&, float a, float b) {  
        return a \* b;  
    }  
};

This approach is considered best practice for several reasons. Declaring the function as a friend makes it a member of the associated entities of custom\_compute, allowing ADL to find it correctly. However, because it is not a member of the surrounding namespace, it does not add to the global overload set for the name tag\_invoke, which helps keep overload sets small and manageable. This is beneficial for compilation times and reduces the risk of unintended interactions with other code.4

### **1.3. Forward-Looking Considerations: The Member CPO Pattern**

While tag\_invoke represents the current state-of-the-art and a significant improvement over previous techniques, the evolution of C++ customization mechanisms has not stopped. A critique has emerged that even tag\_invoke, for all its benefits, still carries the cognitive overhead and complexity of relying on ADL.16 ADL's rules, especially in complex scenarios involving templates and multiple namespaces, can be difficult for developers to reason about.  
In response to this, a new pattern is being proposed and adopted in cutting-edge library designs, such as the Senders and Receivers model for C++ concurrency. This pattern, detailed in P2855R1, advocates for moving away from ADL-based customization entirely in favor of member functions.16 In this model, a  
tag\_invoke customization like:

C++

friend void tag\_invoke(std::execution::start\_t, my\_op\_state& self) noexcept;

becomes a public member function of the customizable type:

C++

void start(std::execution::start\_t) noexcept;

The CPO (std::execution::start) would then be implemented to first check for the existence of a callable member function with the appropriate name before falling back to other mechanisms, or perhaps not falling back at all.  
The primary advantages of this member CPO pattern are its simplicity and explicitness. It completely eliminates ADL from the customization process, relying instead on the much simpler rules of member name lookup.17 This leads to smaller overload sets, which can improve build times and the quality of compiler diagnostics for incorrect calls. Developers can place their types in any namespace without worrying about ADL rules, and the customization point is clearly and explicitly part of the class's public interface.17  
The existence and growing traction of this pattern are highly relevant to the design of the TInCuP tool. It signals that the C++ community's trajectory in library design is one of continuous movement towards greater encapsulation, locality of behavior, and reduced reliance on complex, non-local name lookup mechanisms. The progression from global ADL functions, to namespaced ADL via tag\_invoke, and now to member functions illustrates a clear architectural preference. Any tooling built today should be designed with an awareness of this trend, ideally with an architecture that is flexible enough to accommodate the generation of member CPOs in the future, should that pattern become a widespread standard. This forward-looking perspective is crucial for ensuring the long-term viability and relevance of the TInCuP tool.

## **Analysis of Proposed tag\_invoke Integration Mechanisms**

The user query outlines two distinct strategies for integrating tag\_invoke support into the TInCuP tool. The first, Mechanism (a), is a prescriptive approach focused on proactive code generation. The second, Mechanism (b), is an observational approach centered on the discovery of existing implementations and subsequent optimization. These two proposals represent fundamentally different philosophies about the role of a development tool and carry vastly different implications regarding implementation complexity, developer workflow, and architectural risk. A thorough technical analysis of each is required to form a sound recommendation.

### **2.1. Mechanism (a): Proactive Code Generation**

Mechanism (a) proposes that TInCuP should automatically generate tag\_invoke implementations, specifically a free function and a static method. This proposal must be critically evaluated against the idiomatic C++ patterns established in the preceding section.

#### **Technical Assessment**

The proposal to generate both a free function and a static method contains a significant technical flaw. While a free function is a viable, though suboptimal, way to implement a tag\_invoke overload, a public static method named tag\_invoke is not a functional pattern for the standard tag\_invoke dispatch mechanism. ADL is the mechanism by which tag\_invoke implementations are found, and ADL rules do not search within class scopes. Therefore, a static member function would never be discovered by an unqualified call to tag\_invoke originating from a CPO. This part of the proposal appears to be a conflation of the tag\_invoke pattern with the emerging member CPO pattern and is not viable as stated.  
A generated free function, placed in the same namespace as the customizable type, would be found by ADL. However, this approach is inferior to the hidden friend idiom because it pollutes the enclosing namespace with a tag\_invoke overload. This can increase the size of overload sets for other, unrelated function calls within that namespace, potentially impacting compile times and creating maintenance challenges.  
Given these issues, the most technically sound and beneficial interpretation of this mechanism is a **Refined Proposal (a'): Generation of Hidden Friend Functions**. In this model, TInCuP would be responsible for parsing a class definition and injecting the complete, idiomatic friend R tag\_invoke(cpo\_t, T&,...) boilerplate directly into the private or public section of the class. This aligns perfectly with community best practices and delivers the intended customization without the drawbacks of the originally proposed methods.

#### **Implementation Strategy within TInCuP**

Implementing this refined mechanism is fundamentally a source-to-source transformation task. A naive implementation using text-based templating and regular expressions would be exceedingly brittle and likely to fail when faced with complex class definitions, macros, or varied coding styles.  
A robust implementation necessitates the use of a proper C++ parser to build a semantic understanding of the code. The Clang/LLVM ecosystem provides the ideal infrastructure for this task, specifically the LibTooling library.18 The workflow for TInCuP would be as follows:

1. The tool is invoked on a target source file.  
2. Using LibTooling, TInCuP parses the file into an Abstract Syntax Tree (AST).20  
3. The tool identifies the target class for modification. This could be triggered by a special comment annotation, a base class inheritance, or a user-provided class name.  
4. Once the CXXRecordDecl node for the class is located in the AST, the tool programmatically constructs the text of the required hidden friend tag\_invoke function.  
5. Using Clang's rewriting capabilities, the tool inserts this generated text at the correct location within the class definition in the original source file.

This approach, while more complex than simple text manipulation, is far more resilient and accurate. It leverages the compiler's own understanding of C++ syntax to ensure that the code injection is performed safely and correctly. The scope of the required Clang integration is significant but remains localized to single-file transformations, making it a manageable engineering effort compared to the alternative.

#### **Advantages and Risks**

The primary advantage of this mechanism is its ability to enforce consistency and correctness. It guarantees that every tag\_invoke implementation managed by the tool adheres perfectly to the idiomatic hidden friend pattern, eliminating a common source of developer error. This reduces the cognitive load on developers, who are freed from remembering the precise syntax of tag\_invoke and can instead focus on the implementation logic.7 The implementation of the tool itself, while non-trivial, is a well-understood problem in the domain of Clang-based refactoring tools.  
The risks, however, are noteworthy. A tool that automatically injects code into source files can obscure the codebase's logic. Developers unfamiliar with the tool might be confused about the origin of these friend functions, making the code harder to read and reason about. This approach also creates a tight coupling between the codebase and the TInCuP tool; maintaining the code may become dependent on the tool's availability and proper functioning. If the original proposal of generating non-idiomatic free functions were followed, it would introduce patterns that deviate from community standards, leading to confusion and potential maintenance issues down the line.

### **2.2. Mechanism (b): Discovery and 'Fast Track' Aggregation**

Mechanism (b) represents a far more ambitious and complex vision for TInCuP. It proposes transforming the tool into a static analysis engine capable of discovering all handwritten tag\_invoke implementations across a codebase and using this information to generate an optimized dispatch mechanism—a 'fast track' struct.

#### **Technical Assessment**

This proposal is a sophisticated, whole-program static analysis problem. The 'fast track' struct would presumably be a template that, at compile time, uses if constexpr or SFINAE to check the type of the object being passed to the CPO. If the type is one of the known customizers discovered during the analysis phase, the struct would dispatch the call directly to a function pointer or a direct call to the known implementation, thereby bypassing the compiler's ADL machinery. This could, in theory, offer a micro-optimization by simplifying the work the compiler needs to do during overload resolution.

#### **Implementation Strategy within TInCuP**

Executing this strategy requires building a full-fledged static analysis tool on top of the Clang/LLVM infrastructure. The engineering effort is substantial and involves several complex stages:

1. **Compilation Database Integration:** For any analysis to be accurate, the tool must know the exact compiler flags (include paths, macro definitions, etc.) used to build each file. This requires TInCuP to locate and parse a compile\_commands.json file, which is the standard way Clang-based tools receive this information.19  
2. **Whole-Program AST Parsing:** The tool cannot operate on a single file in isolation. It must parse every relevant translation unit in the project to build a complete map of all tag\_invoke definitions. This involves using Clang's LibTooling to iterate through the compilation database and construct an AST for each entry.19  
3. **AST Matching for Discovery:** Once the ASTs are available, the core of the discovery process involves using Clang's ASTMatcher library. A developer would need to write precise matcher expressions to find all FunctionDecl nodes that meet specific criteria: the function must be named tag\_invoke, it must not be a template definition in many cases, and it must be a non-member function (or a friend).20  
4. **Semantic Validation:** Finding a function named tag\_invoke is insufficient. The tool must then perform semantic analysis on each match to confirm it is a valid customization for the target CPO. This involves inspecting the parameters of the function declaration: verifying that the type of the first parameter is the correct CPO tag type and extracting the type of the second parameter, which is the user's type that is being customized. This requires navigating Clang's complex Type and QualType hierarchies.  
5. **Code Generation of the Dispatcher:** After scanning the entire codebase and building a map from customizable types to their corresponding tag\_invoke implementations, the final step is to generate the 'fast track' C++ header. This generated code would contain the dispatcher struct, likely a highly-templated entity that uses the collected type information to build a series of compile-time checks for direct dispatch.

#### **Advantages and Risks**

The most significant advantage of this approach is the flexibility it affords developers. They are free to write tag\_invoke overloads by hand, following the canonical patterns, without any direct interaction with the TInCuP tool. The tool operates as a transparent optimization layer that adapts to the existing code rather than prescribing its structure. The generated 'fast track' struct offers the potential for a performance improvement by replacing a complex lookup mechanism (ADL) with a more direct form of dispatch, which could be beneficial in performance-critical code paths, particularly in build configurations with limited link-time optimization.  
However, the risks and costs associated with this mechanism are extreme. The implementation complexity is an order of magnitude greater than that of Mechanism (a). It requires deep, specialized expertise in the Clang C++ APIs, which are known for their steep learning curve and lack of long-term stability guarantees across LLVM versions.20 Building and maintaining such a tool is a significant, ongoing engineering investment, comparable to developing a custom  
clang-tidy check or linter.18  
Furthermore, the performance of the tool itself would be a major concern. Full-program static analysis is an inherently slow process, often much slower than compilation.24 Integrating such a tool into a standard build pipeline could dramatically increase build times, negatively impacting developer productivity.  
Finally, the analysis process is inherently fragile. C++ is a language of immense complexity, and it is highly likely that the static analysis would fail to correctly identify all tag\_invoke implementations, especially in the presence of complex template metaprogramming, heavy macro usage, or unconventional coding styles. An incomplete analysis would lead to the generation of an incorrect 'fast track' struct, which could cause subtle and hard-to-diagnose bugs, such as incorrect runtime behavior or even One Definition Rule (ODR) violations. The risk of the tool silently producing a broken optimization is a severe liability.  
The choice between these two mechanisms is therefore not merely technical but strategic. It is a decision about whether TInCuP should be a prescriptive "code writer" that enforces a consistent pattern locally, or an observational "code reader" that attempts to understand the entire program to apply a global optimization. The latter path, while intellectually appealing, introduces a level of complexity and risk that must be carefully weighed against its purported benefits.

## **Comparative Analysis and Strategic Recommendation**

Synthesizing the technical deconstruction of the two proposed mechanisms reveals a stark contrast in their respective costs, benefits, and strategic implications. A direct comparison across several key axes, an exploration of potential hybrid models, and a final, evidence-based recommendation are necessary to chart the optimal path forward for the TInCuP tool.

### **3.1. Feature and Complexity Comparison**

The fundamental differences between the refined proactive generation mechanism and the discovery-based aggregation mechanism can be most clearly illustrated through a comparative table. This table summarizes the trade-offs involved in choosing one path over the other.

| Feature Axis | Mechanism (a): Proactive Generation (Refined) | Mechanism (b): Discovery & Fast-Track |
| :---- | :---- | :---- |
| **Implementation Complexity** | **Medium.** Requires using Clang LibTooling for robust AST rewriting, but the scope is limited to injecting a known code pattern into a single file. | **Very High.** Requires a full Clang-based static analysis pipeline, including compilation database integration, cross-translation-unit analysis, and complex semantic validation.19 |
| **Tool Performance** | **Fast.** Operates on a single file or class at a time. Suitable for interactive use as a pre-commit hook or IDE action. | **Slow.** Requires a full scan of the codebase, comparable in time to a full build or a comprehensive linting pass.24 Unsuitable for interactive developer workflows. |
| **Developer Workflow** | **Prescriptive.** Developers must explicitly use the tool to generate the boilerplate. Handwritten implementations are not part of the managed workflow. | **Flexible.** Developers write code idiomatically by hand. The tool functions as an optional, transparent optimization layer that adapts to their code. |
| **Code Consistency** | **High.** All tag\_invoke implementations generated by the tool will be identical in structure, enforcing a single house style. | **Variable.** Consistency depends on developer discipline and code reviews. The tool only aggregates what it finds, regardless of style variations. |
| **Potential for Optimization** | **None.** Generates standard, idiomatic code that relies on the compiler's normal handling of ADL and its own inlining and optimization passes. | **High (in theory).** The generated 'fast track' struct can replace ADL with direct dispatch, a potential micro-optimization. The real-world benefit is questionable. |
| **Robustness & Fragility** | **Robust.** The logic is simple: find a specific AST node for a class and insert a pre-defined block of text. This is less likely to be broken by complex C++ features elsewhere in the code. | **Fragile.** The analysis is highly sensitive to C++ language complexity, macros, and advanced template metaprogramming. An incomplete analysis could lead to subtly broken builds or incorrect runtime behavior. |
| **Alignment with Idiomatic C++** | **High.** The refined version of the mechanism generates the canonical hidden friend function, which is the community-accepted best practice.14 | **High.** It directly supports and encourages developers to write customizations using the canonical handwritten pattern. |

This comparison makes it clear that while Mechanism (b) offers greater developer freedom and a theoretical performance benefit, it does so at the cost of extreme implementation complexity, poor tool performance, and significant fragility. Mechanism (a), when refined to generate the correct idiom, provides a robust, fast, and consistent solution with a much more favorable cost-benefit ratio.

### **3.2. Exploration of Hybrid Models**

The binary choice between these two extremes is not the only option. Hybrid models that combine the strengths of both approaches can mitigate their respective weaknesses and may represent a more strategic long-term solution.  
**Model 1: Generation with Opt-in Discovery:** A pragmatic hybrid would establish the refined Mechanism (a) as the primary workflow for all CPOs. Developers would use TInCuP to generate the standard hidden friend boilerplate. For specific, performance-critical CPOs where the overhead of ADL is suspected to be a bottleneck, developers could add a special attribute or annotation (e.g., \[\[tincup::fast\_track\]\]) to the CPO definition. This annotation would trigger a targeted run of the Mechanism (b) discovery engine, but its scope would be limited to just that single CPO and its known customizers (which could also be explicitly listed). This approach contains the cost and complexity of the static analysis, applying it only where it has the highest potential impact, while keeping the default workflow simple and fast.  
**Model 2: Linter-Assisted Generation:** A more powerful and strategically aligned hybrid would be to repurpose the complex static analysis engine of Mechanism (b) not as an optimizer, but as a linter. In this model, the engine would scan the codebase to find all handwritten tag\_invoke implementations. Instead of generating a 'fast track' struct, it would validate their correctness against the CPO's definition (correct tag type, argument types, return type, noexcept specification, etc.). It could also identify types that, based on their interface or usage, *should* provide a tag\_invoke customization but currently do not. When the linter finds an issue or a missing implementation, it could then offer a quick fix action to automatically generate a correct skeleton using the logic from Mechanism (a). This transforms TInCuP from a simple generator or a black-box optimizer into an intelligent developer assistant that improves code quality and correctness, a role much more aligned with modern static analysis tools like clang-tidy or SonarQube.18

### **3.3. Final Recommendation**

Based on the comprehensive technical analysis, a definitive recommendation can be made.  
First, the original proposals should be **rejected as stated**. The static method generation in Mechanism (a) is technically non-functional for standard tag\_invoke dispatch. The full-program analysis and 'fast track' generation of Mechanism (b) introduces an unacceptable level of implementation complexity, build-time overhead, and fragility for a benefit that is, at best, a questionable micro-optimization.  
The pursuit of the 'fast track' optimization is likely premature. Modern optimizing compilers are exceptionally effective at handling the idiomatic tag\_invoke pattern. The process works as follows: a CPO call results in an unqualified call to tag\_invoke. At compile time, for a given set of concrete types, the compiler performs ADL to find candidate functions. This lookup is deterministic and resolves to a single, specific overload. This resolved function call is then a prime candidate for inlining. Once inlined, the entire dispatch mechanism, including the ADL, vanishes from the final machine code, leaving only the user's implementation logic. The 'fast track' struct essentially attempts to manually perform this compile-time resolution. While it might save a small amount of work in the compiler's frontend, it is highly unlikely to produce superior machine code compared to what a standard optimizing compiler would generate from the simpler, idiomatic pattern. The real-world performance gain is likely to be negligible or zero in most optimized builds.  
Therefore, the most strategic and valuable path forward is a **phased approach**:

1. **Phase 1 (Short-Term): Implement a Refined Mechanism (a).** The immediate priority should be to develop a robust version of the proactive generation tool. This tool must generate the idiomatic **hidden friend tag\_invoke function** and should be implemented using Clang's LibTooling for accurate and safe AST rewriting. This action provides immediate and significant value by reducing boilerplate, preventing common developer errors, and enforcing a consistent, best-practice implementation across the codebase.14 This approach delivers the majority of the potential benefits for a fraction of the total engineering effort.  
2. **Phase 2 (Long-Term): Investigate a Linter-Assisted Model.** The significant engineering investment required for the static analysis engine of Mechanism (b) should be reframed. Instead of chasing a dubious optimization, this technology should be developed as a powerful linter and developer-assistance tool. This aligns TInCuP with the broader ecosystem of static analysis tools and provides tangible value by finding bugs, enforcing constraints, and identifying opportunities for customization. This approach mitigates the critical risk of the tool silently generating incorrect code and instead focuses its power on improving code quality and developer productivity. The 'fast track' optimization concept should be definitively shelved unless and until rigorous, profile-guided benchmarking on the specific target codebase proves it provides a substantial and necessary performance improvement.

## **Conclusion**

This analysis has evaluated the feasibility of two proposed mechanisms for incorporating tag\_invoke support into the non-public TInCuP tool. The investigation reveals that the choice between proactive code generation and discovery-based optimization is a critical strategic decision with far-reaching consequences for the tool's architecture, complexity, and role within the development workflow.  
Mechanism (a), the proactive generation approach, was found to be flawed as originally proposed due to its inclusion of a non-functional static method pattern. However, when refined to focus exclusively on generating the idiomatic hidden friend tag\_invoke function, it emerges as a highly valuable and pragmatic solution. It promises to reduce boilerplate, enforce consistency, and lower the cognitive burden on developers, all with a manageable implementation complexity leveraging established Clang-based refactoring techniques.  
Conversely, Mechanism (b), the discovery and 'fast track' aggregation approach, represents a massive increase in engineering complexity and architectural risk. While offering developer flexibility and a theoretical performance optimization, the implementation requires building a full-program static analysis engine. This path is fraught with challenges, including slow performance, inherent fragility when parsing complex C++, and a high ongoing maintenance burden. Furthermore, the core premise of its 'fast track' optimization is likely a premature one, as modern compilers are typically capable of optimizing the standard tag\_invoke ADL mechanism just as effectively.  
The final recommendation is to reject both proposals in their original form and instead adopt a strategic, phased approach. The immediate focus should be on implementing the refined version of Mechanism (a), providing a robust boilerplate generation tool that creates correct, idiomatic hidden friend functions. This delivers the most significant value with the least risk. The advanced static analysis capabilities envisioned in Mechanism (b) should be pursued as a long-term strategic investment, but repurposed as a linter and developer-assistance tool. This aligns the evolution of TInCuP with industry best practices for C++ tooling, prioritizing code correctness and quality over a questionable micro-optimization. This course of action will ensure that TInCuP becomes a valuable, robust, and sustainable asset for the development team.

#### **Works cited**

1. Customization point design for library functions – Arthur O'Dwyer, accessed August 26, 2025, [https://quuxplusone.github.io/blog/2018/03/19/customization-points-for-functions/](https://quuxplusone.github.io/blog/2018/03/19/customization-points-for-functions/)  
2. Customization Point Objects / Niebloids \- PV264 Advanced Programming in C++ \- fi muni, accessed August 26, 2025, [https://www.fi.muni.cz/pv264/files/pv264\_s06b\_niebloids.pdf](https://www.fi.muni.cz/pv264/files/pv264_s06b_niebloids.pdf)  
3. Why tag\_invoke is not the solution I want | Barry's C++ Blog, accessed August 26, 2025, [https://brevzin.github.io/c++/2020/12/01/tag-invoke/](https://brevzin.github.io/c++/2020/12/01/tag-invoke/)  
4. "'tag\_invoke' \- An Actually Good Way to Do Customization Points" \- Gašper Ažman, C++ London : r/cpp \- Reddit, accessed August 26, 2025, [https://www.reddit.com/r/cpp/comments/hhvwgt/tag\_invoke\_an\_actually\_good\_way\_to\_do/](https://www.reddit.com/r/cpp/comments/hhvwgt/tag_invoke_an_actually_good_way_to_do/)  
5. tag\_invoke: A general pattern for supporting customisable functions \- Open-Std.org, accessed August 26, 2025, [https://open-std.org/JTC1/SC22/WG21/docs/papers/2019/p1895r0.pdf](https://open-std.org/JTC1/SC22/WG21/docs/papers/2019/p1895r0.pdf)  
6. What are customization point objects and how to use them? \- Stack Overflow, accessed August 26, 2025, [https://stackoverflow.com/questions/53495848/what-are-customization-point-objects-and-how-to-use-them](https://stackoverflow.com/questions/53495848/what-are-customization-point-objects-and-how-to-use-them)  
7. tag\_invoke — ztd.idk 0.0.0 documentation, accessed August 26, 2025, [https://ztdidk.readthedocs.io/en/latest/api/tag\_invoke.html](https://ztdidk.readthedocs.io/en/latest/api/tag_invoke.html)  
8. Custom conversions \- Boost, accessed August 26, 2025, [https://www.boost.org/doc/libs/1\_82\_0\_beta1/libs/json/doc/html/json/conversion/custom\_conversions.html](https://www.boost.org/doc/libs/1_82_0_beta1/libs/json/doc/html/json/conversion/custom_conversions.html)  
9. Is std::tag\_invoke just an object with operator() that perfectly forwards all args to unqualified tag\_invoke call? \- Stack Overflow, accessed August 26, 2025, [https://stackoverflow.com/questions/78658746/is-stdtag-invoke-just-an-object-with-operator-that-perfectly-forwards-all-ar](https://stackoverflow.com/questions/78658746/is-stdtag-invoke-just-an-object-with-operator-that-perfectly-forwards-all-ar)  
10. Customization point object (since C++20) \- cppreference.com, accessed August 26, 2025, [https://en.cppreference.com/w/cpp/ranges/cpo.html](https://en.cppreference.com/w/cpp/ranges/cpo.html)  
11. \[customization.point.object\], accessed August 26, 2025, [https://eel.is/c++draft/customization.point.object](https://eel.is/c++draft/customization.point.object)  
12. How to make tag\_invoke CPO deal uniformly with types matching a meta-predicate/concept and with those types wrapped in reference\_wrapper? \- Stack Overflow, accessed August 26, 2025, [https://stackoverflow.com/questions/78640854/how-to-make-tag-invoke-cpo-deal-uniformly-with-types-matching-a-meta-predicate-c](https://stackoverflow.com/questions/78640854/how-to-make-tag-invoke-cpo-deal-uniformly-with-types-matching-a-meta-predicate-c)  
13. Niebloids and Customization Point Objects | Barry's C++ Blog, accessed August 26, 2025, [https://brevzin.github.io/c++/2020/12/19/cpo-niebloid/](https://brevzin.github.io/c++/2020/12/19/cpo-niebloid/)  
14. Duck Invoke — tag\_invoke for C++11, accessed August 26, 2025, [https://www.bfgroup.xyz/duck\_invoke/](https://www.bfgroup.xyz/duck_invoke/)  
15. bfgroup/duck\_invoke: A simple to use, single header, tag\_invoke utility for C++11. \- GitHub, accessed August 26, 2025, [https://github.com/bfgroup/duck\_invoke](https://github.com/bfgroup/duck_invoke)  
16. Member customization points for Senders and Receivers \- Open-Std.org, accessed August 26, 2025, [https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p2855r0.html](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p2855r0.html)  
17. Member customization points for Senders and Receivers \- Open-Std.org, accessed August 26, 2025, [https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p2855r1.html](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p2855r1.html)  
18. Core Clang Tools, accessed August 26, 2025, [https://clang.llvm.org/docs/ClangTools.html](https://clang.llvm.org/docs/ClangTools.html)  
19. LibTooling — Clang 22.0.0git documentation, accessed August 26, 2025, [https://clang.llvm.org/docs/LibTooling.html](https://clang.llvm.org/docs/LibTooling.html)  
20. How to build a C++ processing tool using the Clang libraries \- Linaro, accessed August 26, 2025, [https://static.linaro.org/connect/yvr18/presentations/yvr18-223.pdf](https://static.linaro.org/connect/yvr18/presentations/yvr18-223.pdf)  
21. How to Build a Clang AST-Based C++ Static Analysis Tool \- freeCodeCamp, accessed August 26, 2025, [https://www.freecodecamp.org/news/clang-ast-based-static-analysis-tools/](https://www.freecodecamp.org/news/clang-ast-based-static-analysis-tools/)  
22. Writing AST matchers for libclang \- @Manu343726 \- C++, accessed August 26, 2025, [https://manu343726.github.io/2017-02-11-writing-ast-matchers-for-libclang/](https://manu343726.github.io/2017-02-11-writing-ast-matchers-for-libclang/)  
23. ingve/awesome-clang \- GitHub, accessed August 26, 2025, [https://github.com/ingve/awesome-clang](https://github.com/ingve/awesome-clang)  
24. Clang Static Analyzer, accessed August 26, 2025, [https://clang-analyzer.llvm.org/](https://clang-analyzer.llvm.org/)  
25. Cppcheck \- A tool for static C/C++ code analysis, accessed August 26, 2025, [https://cppcheck.sourceforge.io/](https://cppcheck.sourceforge.io/)  
26. C++ Static Code Analysis & code quality and security Programming Language \- Sonar, accessed August 26, 2025, [https://www.sonarsource.com/knowledge/languages/cpp/](https://www.sonarsource.com/knowledge/languages/cpp/)